{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c960af35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c78c184d14e131e6aa7a511d926ac526",
     "grade": false,
     "grade_id": "cell-1da0d1c590ff8a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet No. 8\n",
    "\n",
    "---\n",
    "\n",
    "> Machine Learning for Natural Sciences, Summer 2021, Jun.-Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> \n",
    "> Deadline: 14.06.2021, 8 am\n",
    "> \n",
    "> Tutor: chen.zhou@kit.edu  \n",
    "> **Please ask questions in the forum and only contact the Tutor when there are issues with the grading**\n",
    "\n",
    "---\n",
    "**Topic**: This assignment will focus on convolutional neural network for brain tumor image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677f5d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6c3f4be0a16f7b5a11423c3e4d3897d",
     "grade": false,
     "grade_id": "cell-e54f3bf38b55a4a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Preliminaries\n",
    "In this assginment, we are going to use Pytorch instead of Tensorflow to build our neural network. Please shutdown jupyter and run on the command line / anaconda prompt as below:\n",
    "```\n",
    "# Activate aimat\n",
    "conda activate aimat\n",
    "\n",
    "# Install pytorch, torchvision torchaudio library with cuda gup toolkit\n",
    "conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n",
    "\n",
    "# Install ipywidgets library\n",
    "conda install -c conda-forge ipywidgets\n",
    "\n",
    "# Start jupyter again\n",
    "jupyter notebook Exercise06.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb7231-cc1e-4da0-a4db-69376371314f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2f434e7ac6a0b4014da58b754b6d5d8",
     "grade": false,
     "grade_id": "cell-18eae86a8da21038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a1d93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bef19bdc929746b9518c2ac8e972fbe3",
     "grade": false,
     "grade_id": "cell-49cf292b54724ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the purpose of autograding, please:\n",
    "1. Set `do_training=True` while finishing this assignment.\n",
    "2. Please submit your solution with `do_training = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ec518",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f77ae003831fc668c4f278deffb72a6",
     "grade": false,
     "grade_id": "cell-ded537f716d4ca11",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please submit your solution with do_training = False.\n",
    "do_training = False\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012afd9-ddaf-4078-8342-369622175432",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20e424b2349441abc74f5eb1393d353c",
     "grade": false,
     "grade_id": "cell-95457f6c58e25bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the last several assignments, we have implemented and trained fully connected neural network, with the application to chemistry and materal science. This time, we will learn to implement and train a convolutional neural network (CNN) for brain tumor image classification, and compare it with a fully connected neural network to show the power of weight sharing. In addition to that, we will see how a pretrained network can be used to fullfill the same task with better performance through transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fbf5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78e3bba48ff2cbdb0578cdbcd04de45c",
     "grade": false,
     "grade_id": "cell-cb8513bebe730708",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Dataset\n",
    "In this assignment, we will work on the dataset consists of the images of brain x-rays from both healthy people and cancer patients.\n",
    "\n",
    "A brain tumor occurs when abnormal cells form within the brain with unknown reasons. And primary brain tumors occur in around 250,000 people a year globally, making up less than 2% of cancers. The early diagnosis is important when fighting this disease, and medical imaging plays a central role in this field. You may read more about brain tumor from this [paper](https://pubmed.ncbi.nlm.nih.gov/27157931/).\n",
    "\n",
    "This data set was downloaded from [kaggle](https://www.kaggle.com/preetviradiya/brian-tumor-dataset), and only 10% of cancer/not cancer images were selected randomly for this assignment (460 images in total). Now, let's get started with visualizing part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7010b-ef4f-4f0e-bd45-680c86750aff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e4146d6d27bd2924cc4b8030a8707a0",
     "grade": false,
     "grade_id": "cell-f6dde6886883799c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img_dir = './dataset' # path of image directory\n",
    "images = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896e9e5-6a11-454a-8d5c-2c238d2a3fa0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9825c97bea1469bbfa49e3eb956220b4",
     "grade": false,
     "grade_id": "cell-927bc59378df48fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot 10 x-ray images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(40,20), gridspec_kw=dict(hspace=0.1, wspace=0.3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(Image.open(os.path.join(img_dir, images[i])))\n",
    "    ax.set_title(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf1fb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6afb81d18fa1a50da9f59a08a8df91b8",
     "grade": false,
     "grade_id": "cell-e03ff8d281630822",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "From the plot above we can see that images in the dataset vary by several features, such as brightness, direction the images were taken, and of course have tumor or not. For such a complicated dataset, is it possible to classify it with a simple classifier like k-nearest neighbors? The principal component analysis can give us a hand on this problem.\n",
    "\n",
    "PCA is an unsupervised technique to project the data to lower dimensional space through linear (linear PCA) or non-linear (kernel PCA) combinations of the data's original features. The \"Principal Component\" stands for combination results of features that are most important for accounting the variance in the dataset. PCA can be used to visualize high-dimensional data, filter out noise, or as feature selector to accelerate the learning process. Here, we will take this advantage to visualize the most important features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a770553-b3ef-409c-8f77-b5c3e23c2dbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f286879a500b83c20f37ac0183c731d5",
     "grade": false,
     "grade_id": "cell-87fb0bcc79cd5157",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare data in numpy array for PCA()\n",
    "data = []\n",
    "for i in images:\n",
    "    img = Image.open(os.path.join(img_dir, i)).convert('L').resize((256,256))\n",
    "    data.append(np.array(img).flatten())\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7918a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c5d6ecc537aa7aeb43d75de8eeaa657",
     "grade": false,
     "grade_id": "cell-03eafe24d8cff8e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please use the `PCA()` to perform principal component analysis on `data`. Use the parameter `n_components` to set the amount of variance that needs to be explained to be 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e50dea-a7c6-4af8-a76f-193765ec6918",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93b3d0526687643fb52f31b6b8d0369a",
     "grade": false,
     "grade_id": "cell-c58aaa5b6168268d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pca = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa853ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e246acc04c1521f1daaa30e748778b8",
     "grade": true,
     "grade_id": "cell-0bc21e0d45ce328d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# PCA - 1 point\n",
    "assert isinstance(pca, PCA), \"pca should be an instance of the sklearn PCA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1ffce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d7831a3c3dc77831ad490b675e59c7d",
     "grade": false,
     "grade_id": "cell-3630eebe8ffff6ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's visualize the images associated with the first several principal components, which may give us some insight about what make these images vary from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033f39d-ed3e-4b67-b467-9187dc9858b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a66e5ba8bf6506beae79c2e34d13da7",
     "grade": false,
     "grade_id": "cell-455941975389eb8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize the first 10 principal components\n",
    "fig, axes = plt.subplots(2, 5, figsize=(40, 20), gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(256, 256), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5fca6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b40798d24e1ee7569aba913f6aa9c2d",
     "grade": false,
     "grade_id": "cell-e0652fd2149d41c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As seen above, the first two images on the top left seem to be associated with the brightness of the x-ray image, while the later ones on the bottom right seem related to the direction or size of the skull. Since none of them displays strong relationship to the shape/size/location of the brain tumor, it is difficult to classify cancer/not cancer images with a simple algorithm, which may focus more on those more 'obvious' features. As a result, a more sophisticated model like neural network is more suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532e16e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07a0a513e9e0c3c02b3ad7d6429db6cd",
     "grade": false,
     "grade_id": "cell-6a2e5f7b88533c14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data processing\n",
    "To begin with, we need to obtain and organize all image metadata with `pandas`. Please use `pd.Series` for `img_names` and `img_labels`, together with `pd.concat()` and `pd.DataFrame` to construct `tumor_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b49a3a-bbcf-43c5-8fc5-9228f034e2f0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd426e83113bbb52e557c3e21df5c6ee",
     "grade": false,
     "grade_id": "cell-f2038a6ccb8058c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# implement tumor_df as pd.DataFrame for train/test split and further data process\n",
    "img_names = [] # list contains image name\n",
    "img_labels = [] # list contains labels (0 as not cancer, 1 as cancer)\n",
    "tumor_df = None\n",
    "for i in images:\n",
    "    img_names.append(i)\n",
    "    img_labels.append(0 if 'Not Cancer' in i else 1)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af9596",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e4b021d7e726360747d9ec0096e77d0",
     "grade": true,
     "grade_id": "cell-8061059dcf86247d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(tumor_df) == 460, 'Please check the set up of tumor_df'\n",
    "assert tumor_df[\"label\"].value_counts()[1] == 252\n",
    "assert tumor_df[\"label\"].value_counts()[0] == 208"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51178f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e96cb6e8b22fd00b1de594c1feb30674",
     "grade": false,
     "grade_id": "cell-7d30abd310b8f82b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, for the training/test set generation, please use the `train_test_split()` to split the `tumor_df` into `train_set` and `test_set`. This time, we will use 80% of the data for training and the rest for test.\n",
    "\n",
    "Please fix the `random_state` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ac747-a833-4823-b822-a1c57b07ddca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2cda224b6a52cca06edd8bfa46c0f13",
     "grade": false,
     "grade_id": "cell-e33a37c6ea1a2464",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# training set/test set split\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78899fdf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbb48d8f3c0d970a4fb2af7fa820d933",
     "grade": true,
     "grade_id": "cell-e479d06796757aae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train-test split 1 point\n",
    "assert train_set.shape == (368, 2)\n",
    "assert test_set.shape == (92, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202565b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94d50d41abddddb9e4d94b6c0c467885",
     "grade": false,
     "grade_id": "cell-9f6286c040c18dd3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pytorch offers convenient APIs for handling data: `Dataset` and `DataLoader`, which achieve data loading/processing with better readability and modularity. Take the following implementation as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b274b43-9f8e-459b-8c54-94598a1bb301",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "569a55276baf79db7f0ec8f6d1b8fe31",
     "grade": false,
     "grade_id": "cell-505e3b65ddc27ff5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TumorImageDataset(Dataset):\n",
    "    \"\"\"load, transform and return image and label\"\"\"\n",
    "    def __init__(self, annotations_df, img_dir, transform=None):\n",
    "        self.img_labels=annotations_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image path according to idx\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # convert all image to RGB format\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        # apply image transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb14d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec53cac592a71e62f3b6849bec3a50a9",
     "grade": false,
     "grade_id": "cell-600ac4a77b30dbf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please finish the `image_transform` module. The image should be resized to $256\\times 256$ then cropped at center to size $244 \\times 244$. You may use `transforms.Resize()` and `transforms.CenterCrop()` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e4172-34f8-461d-b3f8-2669c5e87f36",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1efe3b68f5367a846aac6ea08e44680",
     "grade": false,
     "grade_id": "cell-96a3bdb0a80f45b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# user defined image transform process\n",
    "# here we resize and cut the center of each image to obtain dataset with uniform size\n",
    "image_transform = transforms.Compose([\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7dbb8-e7d5-44c5-b46e-ad7d27d1fb2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ae43be7ba75ae01bafca652b782b83",
     "grade": false,
     "grade_id": "cell-a41ca969e64f7962",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# implement Dataset and DataLoader for training\n",
    "train_data = TumorImageDataset(train_set, img_dir, image_transform)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "test_data = TumorImageDataset(test_set, img_dir, image_transform)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "image_datasets = {'train': train_data, 'test': test_data}\n",
    "image_dataloaders = {'train': train_dataloader, 'test': test_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b27ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f4bdbe955c131da4ade1c02cd4f3f7c",
     "grade": true,
     "grade_id": "cell-be99e173d352a2ac",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "feat, labels = next(iter(train_dataloader))\n",
    "assert feat.shape[2] == 244 and feat.shape[3] == 244, \"Wrong size, please check image_transform\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954051a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f55b6528631934e9169206566d264363",
     "grade": false,
     "grade_id": "cell-aa5c269e894ec6aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is a plot for part of the dataset with `train_dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c62ee8-24b1-4435-863c-446a8427d88a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e66fb79d5b9a02052798e5f8186b3af3",
     "grade": false,
     "grade_id": "cell-648363a3d49dc0ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot a batch (32) of image in training set\n",
    "train_features, train_labels = next(iter(train_dataloader)) # DataLoader is iterable\n",
    "fig, axes = plt.subplots(4, 8, figsize=(40,20), gridspec_kw=dict(hspace=0.1, wspace=0.3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(train_features[i].numpy().transpose((1, 2, 0)))\n",
    "    ax.set_title('Cancer' if int(train_labels[i]==1) else 'Not Cancer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a10e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bed72eba929fe8957bbe72d93aaada1f",
     "grade": false,
     "grade_id": "cell-7e1e3361387e319a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Build the neural network\n",
    "## motivation of CNN: compare with fully connected layers\n",
    "As discussed in the class, an advantage of convolutional neural network (CNN) is weight-sharing during the convolutional steps that significantly reduces the amount of calculations and speed up the training process. Let's demonstrate this effect by looking at a densely connected NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef3e86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c34b3cb2a34bc86ce544e18b2fa649c",
     "grade": false,
     "grade_id": "cell-5832647023fde8ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pytorch builds neural network by subclassing the `nn.Module`. For each `nn.Module`, there is a `forward()` method implementing operations on input data.\n",
    "\n",
    "We implement the `DenseNet` with three fully connected layers. Please finish the `forward()` method function using `self.fc1`, `self.fc2`, `self.fc3` that have already been already defined. For the first two layers, there is a `F.relu()` activation function for each of them. For the output layer, we use `torch.sigmoid()` to generate outcome between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58395c-984a-443e-b040-d16d45a15d13",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b783b0925e7eccacdc8bc0ffba0115",
     "grade": false,
     "grade_id": "cell-16b77cd218f29cfb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    \"\"\"A three layer fully connected neural network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=244*244*3, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=1)\n",
    "    def forward(self, x):\n",
    "        \"\"\"Operations on x\"\"\"\n",
    "        x = torch.flatten(x, 1)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad39694",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ccfc4284d094a28fe76923f3ec13741",
     "grade": true,
     "grade_id": "cell-d3885b5a7993e5dc",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dense_model = DenseNet().to(device)\n",
    "\n",
    "assert len(dense_model.state_dict().keys()) == 6, 'please check if there is any fc layer mising in forward()'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719762a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "785c00622256696a5c8e20cb92e59868",
     "grade": false,
     "grade_id": "cell-e0b232bcf59dea20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unfortunately, Pytorch does not support the build-in method to display model infomation (such as the `summary()` method in Tensorflow). Luckily this can be easily implemented. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eec21d-1b8f-4e43-a54d-733f823b4d97",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec297c964b680ff3b89fffffc6703ed6",
     "grade": false,
     "grade_id": "cell-b6474c1d775dd8b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def summary(model):\n",
    "    \"\"\"Print out model architecture infomation\"\"\"\n",
    "    parameter_count = 0\n",
    "    model_info = model.state_dict()\n",
    "    for name, module in model.named_children():\n",
    "        # loop each module in the model to record number of parameters\n",
    "        try:\n",
    "            n_weight = model_info[name+'.weight'].flatten().shape[0]\n",
    "            n_bias = model_info[name+'.bias'].flatten().shape[0]\n",
    "        except:\n",
    "            n_weight = 0\n",
    "            n_bias = 0\n",
    "        print('{} layer (No. of weight: {:n}, No. of bias: {:n})'.format(name, n_weight, n_bias))\n",
    "        parameter_count += (n_weight + n_bias)\n",
    "    print('Total parameters: {:n}'.format(parameter_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e81a57-0450-4a38-87fd-392c297bd515",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dad2b2ddc32b42ff8ed7a3f14fcf380d",
     "grade": false,
     "grade_id": "cell-84cc8ce966152000",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "summary(dense_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d80cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "633228c0eea80d009cc1384955fa1046",
     "grade": false,
     "grade_id": "cell-224de6ad1f61687b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training\n",
    "As seen from the `summary()` result, dense network dealing with images can become very large (more than $1e7$ parameters in this case). This can lead to problems such as long training time. Please try to train this network for 1 epoch to get an idea about it, using the `train_model()` function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1f87a-82f8-4599-adb0-71e6308d6d60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f89fcaee2acff07d04114416e52eb64f",
     "grade": false,
     "grade_id": "cell-d9019b4a6f0307d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_func, optimizer, epochs, image_datasets, image_dataloaders, do_training=True):\n",
    "    \"\"\"Return the trained model and train/test accuracy/loss\"\"\"\n",
    "    if do_training == False:\n",
    "        return None, None\n",
    "    history = {'train_loss':[], 'train_acc':[], 'test_loss': [], 'test_acc': []}\n",
    "    for e in range(1, epochs+1):\n",
    "        print('Epoch {}/{}'.format(e, epochs))\n",
    "        for phase in ['train', 'test']:\n",
    "            if(phase == 'train'):\n",
    "                model.train() # set model to training mode for training phase\n",
    "            else:\n",
    "                model.eval() # set model to evaluation mode for test phase\n",
    "            \n",
    "            running_loss = 0.0 # record the training/test loss for each epoch\n",
    "            running_corrects = 0 # record the number of correct predicts by the model for each epoch\n",
    "            \n",
    "            for features, labels in image_dataloaders[phase]:\n",
    "                # send data to gpu if possible\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # reset the parameter gradients after each batch to avoid to avoid double-counting\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward pass\n",
    "                # set parameters to be trainable only at training phase\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outcomes = model(features)\n",
    "                    pred_labels = outcomes.round() # round up forward outcomes to get predicted labels\n",
    "                    labels = labels.unsqueeze(1).type(torch.float)\n",
    "                    loss = loss_func(outcomes, labels) # calculate loss\n",
    "                    \n",
    "                    # backpropagation only for training phase\n",
    "                    if(phase == 'train'):\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # record loss and correct predicts of each bach\n",
    "                running_loss += loss.item() * features.size(0)\n",
    "                running_corrects += torch.sum(pred_labels == labels.data)\n",
    "            \n",
    "            # record loss and correct predicts of each epoch and stored in history\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            history[phase+'_loss'].append(epoch_loss)\n",
    "            history[phase+'_acc'].append(epoch_acc)\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eec65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d066d47bdaeba57d021588c8fb3d1c4",
     "grade": false,
     "grade_id": "cell-54541eb2035ac424",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For binary classification, we will use Binary Cross Entropy `BCELoss()` as loss function (read more infomation in [documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)). We use `optim.Adam()` for optimization, which controls the learning rate decay by taking into account both the first and second moment of the gradients. For detailed explanation, you may read the original paper from 2015 [here](https://arxiv.org/abs/1412.6980) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76581567-b55c-4f23-b912-bac47a78a8df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "873e51dc0d9052b1bbc727838ba23485",
     "grade": false,
     "grade_id": "cell-a37cc3412f543c3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(dense_model.parameters(), lr=0.001)\n",
    "dense_model_trained, history = train_model(dense_model, loss, optimizer, 1, image_datasets, image_dataloaders, do_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda7af1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aabb30803a434419fcff9fe1f2dd01ef",
     "grade": false,
     "grade_id": "cell-6277c97224d0cc41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Convolutional Neural Network \n",
    "Now, let's build our own CNN `TumorNet`. Please finish the convolutional part in `forward()`:\n",
    "1. Use `self.conv` as the convolutional layer with the `F.relu()` activation function.\n",
    "2. Add max pooling layer `self.pool`. \n",
    "3. The feature map is then flattened and feed into `self.fc1` with `F.relu()` activation function.\n",
    "4. We will then use `self.dropout` for regularization.\n",
    "5. Use `self.fc2` as output layer with `torch.sigmoid()` as activation function.\n",
    "\n",
    "![CNN](./img/TumorNet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe7b76",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c6f7a97e005659310df3afec8b29e3b",
     "grade": false,
     "grade_id": "cell-b45ecccf6a9e4b09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TumorNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN with:\n",
    "        one convolutional layer\n",
    "        one max pooling layer\n",
    "        two fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TumorNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(in_features=60*60*16, out_features=64)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Operations on x\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78687b74-913d-4f4b-9585-da1e1c3eda43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "556ca20e3bd3bfabd5eda567ae1c8968",
     "grade": true,
     "grade_id": "cell-e36b5ba6885136aa",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = TumorNet().to(device)\n",
    "summary(cnn_model)\n",
    "\n",
    "assert 'conv.weight' in cnn_model.state_dict().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d09e34-9cce-46eb-a00a-3046f3fd52ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63417c6f6bb50dd78a30dae6fa2f99b5",
     "grade": false,
     "grade_id": "cell-e14cffd9d3add841",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "cnn_model_trained, cnn_history = train_model(cnn_model, loss, optimizer, 15, image_datasets, image_dataloaders, do_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a175cee0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9adca45f2f2ee1fdb6917260db29b63",
     "grade": false,
     "grade_id": "cell-ffc79766fd81a70d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please enter your final **test accuracy** after 15 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72dcb14",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb8322e58ded67de38a3cba76ceeeab",
     "grade": false,
     "grade_id": "cell-482e122509acb638",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_acc = (\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505b99d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cb66742907aecec2e7a619671418cbf",
     "grade": true,
     "grade_id": "cell-7ea6eab9a4566fa0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert test_acc or test_acc < 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4840ba5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faed2b6b235a6255c2b4dce6444cd95b",
     "grade": false,
     "grade_id": "cell-4f16f722063f6aaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we plot the training curve to visualize the loss and accuracy vs. epoch for both training and test process.\n",
    "Note the hyperparameters of this model is not optimized yet. Feel free to give a try on hyperparameter optimization for better result. But please do it in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2d2eb-6521-44c8-b69e-ae7ec7c51986",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12b4c9f7897c3601292470620b678377",
     "grade": false,
     "grade_id": "cell-411c156c6b081bdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_curve(history):\n",
    "    '''Plot the training curve'''\n",
    "    train_loss = history['train_loss']\n",
    "    test_loss = history['test_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    test_acc = history['test_acc']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "    ax1.plot(list(range(1, len(train_loss)+1)), train_loss, label='Training', color='c')\n",
    "    ax1.plot(list(range(1, len(train_loss)+1)), test_loss, label='Test', color='b')\n",
    "    x_major_locator=MultipleLocator(1)\n",
    "    ax1.set_xlim(1,len(train_loss))\n",
    "    ax1.xaxis.set_major_locator(x_major_locator)\n",
    "    ax1.set_xlabel('Eopchs')\n",
    "    ax1.set_ylabel('Binary Cross Entropy Loss')\n",
    "    ax1.legend(loc='upper right',fontsize='x-large')\n",
    "    ax1.set_title('Loss vs. Epochs')\n",
    "    \n",
    "    ax2.plot(np.arange(1, len(train_acc)+1), train_acc, label='Training', color='c')\n",
    "    ax2.plot(np.arange(1, len(train_acc)+1), test_acc, label='Test', color='b')\n",
    "    x_major_locator=MultipleLocator(1)\n",
    "    ax2.set_xlim(1,len(train_acc))\n",
    "    ax2.xaxis.set_major_locator(x_major_locator)\n",
    "    ax2.set_xlabel('Eopchs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend(loc='lower right',fontsize='x-large')\n",
    "    ax2.set_title('Accuracy vs. Epochs')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353571b3-0900-44ac-a49b-db628355f6a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bd2d79cb7511aa1cc15134fd92ddc6d",
     "grade": false,
     "grade_id": "cell-4afaabad5f66ad0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_training_curve(cnn_history)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff084862",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30bec0463b6e25a1b4f803a31b0c4f00",
     "grade": false,
     "grade_id": "cell-7c8de36b4d0bcaa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Transfer learning\n",
    "In practice, people tend to start with pretrained models instead of training an entire Convolutional Network from scratch. The idea is to take the advantage of a preexisting model, which is trained on a very large dataset, through transfer learning to achieve both better performance and faster convergence. This is particularly useful when training with a dataset of which the size is not sufficient, such as the case we have in this assignment (You may have already noticed the lack of stability during the training of `cnn_model` earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3386c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c37c9a60954af6b4f0412efcfda752f0",
     "grade": false,
     "grade_id": "cell-232ca24810169c37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are two major scenarios where transfer learning is used:\n",
    "1. Finetuning the CNN: Instead of random initialization, the network was firstly initialized with a pretrained network, then trained on the target dataset. In this scenario, parameters in both convolutional and fully connected layers are trainable.\n",
    "2. Used as feature extractor: In this case, all layers except the last fully connected layer were used as feature extractor of which parameters are freezed. The last fc layer is replaced in accordance with the target dataset and its parameters are trainable.\n",
    "\n",
    "For more infomation about transfer learning, take a look at the [note](https://cs231n.github.io/transfer-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2f66e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7031b14ffe17ca0ad309c9cdec9eb1fa",
     "grade": false,
     "grade_id": "cell-13dd8dfd21f3640c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment, we are going to take the second choice and use ResNet18 as our pretrained feature extractor. \n",
    "ResNet, or residual network, is a neural network architecture that applies identity mapping as a \"shortcut connections\" (see figure below). This architecture overcomes the problem named as \"vanishing gradients\" of deep neural network that causes the decrease of prediction accuracy when number of layer increase. For more infomation, please read the original [paper](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "![resnet](./img/ResNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd7ad3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8821cff08d083dd34062e3a9aff14ce",
     "grade": false,
     "grade_id": "cell-c99437ea2bd5aa7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To use ResNet18 as a feature extractor, we first need to load the model and freeze all parameters. Please finish the rest steps as described here:\n",
    "1. Replace the last fully connected layer with the desired module for tumor classification task. You may use Pytorch `nn.Sequential` module to concatenate `nn.Linear(in_features, out_features)` and `nn.Sigmoid`. You may use `resnet_model.fc.in_features` to obtain `in_features`. The `out_features` should be 1 since we are working on the binary classification problem with single output node.\n",
    "2. Assign the result Sequential module to the last layer of pretrained model `resnet_model.fc`.\n",
    "\n",
    "Do not worry about setting the parameters of the last layer to be trainable, as newly constructed modules have `requires_grad=True` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966036d5-ebba-4985-b851-dc911b8860b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cfd3db9832463aa34c9a426685fa012",
     "grade": false,
     "grade_id": "cell-d50994778c5d8796",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load the pretrained ResNet18 model\n",
    "resnet_model = torchvision.models.resnet18(pretrained=True).to(device)\n",
    "for p in resnet_model.parameters():\n",
    "    # freeze all parameters\n",
    "    p.requires_grad = False\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9d594",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21a0947ce193eb7b94bd5c33f36cd1c2",
     "grade": false,
     "grade_id": "cell-6cba5871e60cd982",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's train this model and compare it with the CNN model implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14014fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79a7b64a8a793d1ba5fa8fa5c151ee8f",
     "grade": false,
     "grade_id": "cell-df333fbc365169a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
    "resnet_trained, resnet_history = train_model(resnet_model, loss, optimizer, 20, image_datasets, image_dataloaders, do_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571b2f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "557d18ce7a25d29442d78f01e54aa69a",
     "grade": false,
     "grade_id": "cell-1e5fd9f062d794a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please the final **test accuracy** for the `resnet_model` after 20 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327310d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "684baea30514b08d36f4f02a30d786bb",
     "grade": false,
     "grade_id": "cell-4e8ac8f2e3743767",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_acc = (\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482f865",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26a96a3ced3b7ed64ebd40968d6d704a",
     "grade": true,
     "grade_id": "cell-70370d8854df1589",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert test_acc or test_acc < 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef6c95-43e6-4e2a-81ac-c070774d39f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41ccbce325303f67dfaeff92cecf2e72",
     "grade": false,
     "grade_id": "cell-e6d82414cf526d64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    plot_training_curve(resnet_history)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7189a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bd9188ad21d53f6ed771aee23aa3913",
     "grade": true,
     "grade_id": "cell-2aa3de44cb2f1585",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please set do_training at the begining of this assignment to False. Thank you!\n",
    "assert do_training == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a25bfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8767492ce4c4a353e11e555bafad9e40",
     "grade": false,
     "grade_id": "cell-3972d28a22191913",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hope you enjoy this assignment. Thank you very much!\n",
    "**This is the end of the assignment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
